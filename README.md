# Gender and Emotion Detection System

Um sistema de detecÃ§Ã£o e classificaÃ§Ã£o de gÃªnero e emoÃ§Ã£o em tempo real usando YOLO11 e OpenCV.

![Demo Screenshot](screenshot.png)

## ğŸ“‹ DescriÃ§Ã£o

Este projeto implementa um sistema completo de detecÃ§Ã£o facial com classificaÃ§Ã£o de gÃªnero e emoÃ§Ã£o em tempo real. O sistema utiliza trÃªs modelos YOLO:
- **YOLOv11n-face**: Para detecÃ§Ã£o de faces
- **Gender Classification Model**: Para classificaÃ§Ã£o de gÃªnero (masculino/feminino)
- **Emotion Classification Model**: Para classificaÃ§Ã£o de emoÃ§Ãµes (disgust, happy, neutral, surprise, unknown)

## âœ¨ CaracterÃ­sticas

- âœ… DetecÃ§Ã£o de faces em tempo real
- âœ… ClassificaÃ§Ã£o de gÃªnero (Male/Female)
- âœ… ClassificaÃ§Ã£o de emoÃ§Ãµes (5 categorias)
- âœ… Interface visual com bounding boxes estilizados
- âœ… ConfiguraÃ§Ã£o flexÃ­vel via arquivo JSON
- âœ… Suporte para webcam e arquivos de vÃ­deo
- âœ… AplicaÃ§Ã£o de blur nas faces (conformidade LGPD)
- âœ… Redimensionamento automÃ¡tico da janela

## ğŸ› ï¸ InstalaÃ§Ã£o

### PrÃ©-requisitos

- Python 3.8+
- Webcam (para detecÃ§Ã£o em tempo real)

### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/educastelo/GenderEmotionDetector.git
cd GenderEmotionDetector
```

### 2. Instale as dependÃªncias

```bash
pip install -r requirements.txt
```

### 3. Configure os modelos

âš ï¸ **Importante**: Os modelos `gender.pt` e `emotion.pt` nÃ£o estÃ£o incluÃ­dos neste repositÃ³rio pois foram treinados por mim. Para usar este projeto, vocÃª precisarÃ¡:

1. **Treinar seus prÃ³prios modelos** usando YOLO11-cls:
   - Para gÃªnero: Crie um dataset com imagens categorizadas como 'male' e 'female'
   - Para emoÃ§Ã£o: Crie um dataset com as categorias: 'disgust', 'happy', 'neutral', 'surprise', 'unknown'

2. **Exemplo de treinamento com YOLO11-cls**:
   ```python
   from ultralytics import YOLO
   
   # Treinar modelo de gÃªnero
   model = YOLO('yolo11n-cls.pt')
   model.train(data='path/to/gender/dataset', epochs=100)
   
   # Treinar modelo de emoÃ§Ã£o
   model = YOLO('yolo11n-cls.pt')
   model.train(data='path/to/emotion/dataset', epochs=100)
   ```

3. **Salvar os modelos treinados** na pasta `models/` com os nomes:
   - `models/gender.pt`
   - `models/emotion.pt`

O modelo `yolov11n-face.pt` pode ser baixado ou vocÃª pode usar um modelo YOLO prÃ©-treinado para detecÃ§Ã£o de faces.

## ğŸš€ Uso

### ExecuÃ§Ã£o bÃ¡sica

```bash
python face_detect.py
```

### ConfiguraÃ§Ã£o

Edite o arquivo `face_config.json` para personalizar o comportamento:

```json
{
    "confidence_face": 0.3,        // ConfianÃ§a mÃ­nima para detecÃ§Ã£o de faces
    "confidence_gender": 0.3,      // ConfianÃ§a mÃ­nima para classificaÃ§Ã£o de gÃªnero
    "confidence_emotion": 0.3,     // ConfianÃ§a mÃ­nima para classificaÃ§Ã£o de emoÃ§Ã£o
    "resize_resolution": "1280x720", // ResoluÃ§Ã£o da janela de exibiÃ§Ã£o
    "source_video": 0              // Fonte de vÃ­deo (0 = webcam, "path/video.mp4" = arquivo)
}
```

### Controles

- **'q'**: Sair do programa

## ğŸ“ Estrutura do Projeto

```
GenderEmotionDetector/
â”œâ”€â”€ face_detect.py          # Script principal
â”œâ”€â”€ face_config.json        # Arquivo de configuraÃ§Ã£o
â”œâ”€â”€ requirements.txt        # DependÃªncias Python
â”œâ”€â”€ screenshot.png          # Imagem de demonstraÃ§Ã£o
â”œâ”€â”€ models/                 # Pasta dos modelos
â”‚   â”œâ”€â”€ yolov11n-face.pt   # Modelo de detecÃ§Ã£o de faces
â”‚   â”œâ”€â”€ gender.pt          # Modelo de classificaÃ§Ã£o de gÃªnero (nÃ£o incluÃ­do)
â”‚   â””â”€â”€ emotion.pt         # Modelo de classificaÃ§Ã£o de emoÃ§Ã£o (nÃ£o incluÃ­do)
â””â”€â”€ README.md              # Este arquivo
```

## ğŸ¯ Funcionalidades TÃ©cnicas

### DetecÃ§Ã£o e ClassificaÃ§Ã£o
- Utiliza YOLO11 para detecÃ§Ã£o eficiente de faces
- Processamento em tempo real com otimizaÃ§Ãµes de performance
- ClassificaÃ§Ã£o simultÃ¢nea de gÃªnero e emoÃ§Ã£o

### Interface Visual
- Bounding boxes com cantos destacados em verde/magenta
- Labels informativos com fundo colorido
- AplicaÃ§Ã£o automÃ¡tica de blur para privacidade (LGPD)

### Configurabilidade
- Thresholds de confianÃ§a ajustÃ¡veis para cada modelo
- Suporte a diferentes resoluÃ§Ãµes de exibiÃ§Ã£o
- Compatibilidade com mÃºltiplas fontes de vÃ­deo

## ğŸ”§ PersonalizaÃ§Ã£o

### Adicionando Novas EmoÃ§Ãµes

Para adicionar novas categorias de emoÃ§Ã£o, modifique a lista `CLASSES_EMOTION` no arquivo `face_detect.py`:

```python
CLASSES_EMOTION = ['disgust', 'happy', 'neutral', 'surprise', 'unknown', 'angry', 'sad']
```

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT.

## ğŸ‘¨â€ğŸ’» Autor

**Eduardo** - *Desenvolvimento Inicial*

## ğŸ™ Agradecimentos

- [Ultralytics](https://ultralytics.com/) pelo framework YOLO11
- [OpenCV](https://opencv.org/) pela biblioteca de visÃ£o computacional
- [Supervision](https://supervision.roboflow.com/) pelas ferramentas de anotaÃ§Ã£o

---

**Nota**: Este projeto foi desenvolvido para fins educacionais e de demonstraÃ§Ã£o. Certifique-se de estar em conformidade com as leis de privacidade locais ao usar sistemas de detecÃ§Ã£o facial.
